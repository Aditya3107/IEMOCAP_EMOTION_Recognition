{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "import matplotlib.style as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Audio Vectors\n",
    "Now that the labels have been extracted, we'll use the compiled csv (df_iemocap.csv) to split the original wav files into multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('/home/mds-student/Documents/aDITYA/multimodal-speech-emotion-recognition-master/Preprocessing/df_iemocap/df_iemocap_5.csv')\n",
    "iemocap_dir = '/home/mds-student/Documents/aDITYA/spec_augment-master/IEMOCAP_full_release_withoutVideos/Iemocap_sentences/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells take some time until completely executed. We can use all 5 seasons at a time but due to memory constraints I have taken each session individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [05:12<00:00, 10.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "for sess in [5]:  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}Session{}/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "        orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "        for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "            start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "            audio_vectors[truncated_wav_file_name] = orig_wav_vector\n",
    "    with open('/home/mds-student/Documents/aDITYA/multimodal-speech-emotion-recognition-master/Preprocessing/AudioVectors/audio_vectors_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
